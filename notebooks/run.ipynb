{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = load_dataset(\"zh-plus/tiny-imagenet\", split=\"train\")\n",
    "test_dataset = load_dataset(\"zh-plus/tiny-imagenet\", split=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        if self.transform:\n",
    "            sample[\"image\"] = self.transform(sample[\"image\"])\n",
    "        if sample[\"image\"].shape[0] == 1:\n",
    "            sample[\"image\"] = sample[\"image\"].repeat(3, 1, 1)\n",
    "        return sample\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_dataset, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = CustomDataset(test_dataset, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siharini/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_dataset = datasets.STL10(\n",
    "    \"/Users/siharini/github/DL-Project/src/data\",\n",
    "    split=\"train\",\n",
    "    download=False,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=0, drop_last=False, shuffle=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.STL10(\n",
    "    \"/Users/siharini/github/DL-Project/src/data\",\n",
    "    split=\"test\",\n",
    "    download=False,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2 * batch_size,\n",
    "    num_workers=10,\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'label'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siharini/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/siharini/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "model = torchvision.models.resnet18(pretrained=False, num_classes=200).to(device)\n",
    "checkpoint = torch.load(\"checkpoint_0100.pth.tar\", map_location=device)\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "\n",
    "for k in list(state_dict.keys()):\n",
    "\n",
    "    if k.startswith(\"backbone.\"):\n",
    "        if k.startswith(\"backbone\") and not k.startswith(\"backbone.fc\"):\n",
    "            # remove prefix\n",
    "            state_dict[k[len(\"backbone.\") :]] = state_dict[k]\n",
    "    del state_dict[k]\n",
    "\n",
    "log = model.load_state_dict(state_dict, strict=False)\n",
    "assert log.missing_keys == [\"fc.weight\", \"fc.bias\"]\n",
    "# freeze all layers but the last fc\n",
    "for name, param in model.named_parameters():\n",
    "    if name not in [\"fc.weight\", \"fc.bias\"]:\n",
    "        param.requires_grad = False\n",
    "\n",
    "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "assert len(parameters) == 2  # fc.weight, fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    top1_train_accuracy = 0\n",
    "    for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "        x_batch = x_batch\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "        top1_train_accuracy += top1[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    top1_train_accuracy /= counter + 1\n",
    "    top1_accuracy = 0\n",
    "    top5_accuracy = 0\n",
    "    for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "\n",
    "        top1, top5 = accuracy(logits, y_batch, topk=(1, 5))\n",
    "        top1_accuracy += top1[0]\n",
    "        top5_accuracy += top5[0]\n",
    "\n",
    "    top1_accuracy /= counter + 1\n",
    "    top5_accuracy /= counter + 1\n",
    "    print(\n",
    "        f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
